{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "from settings import EXPERIMENTS_DIR\n",
    "from experiment import Experiment\n",
    "from utils2 import to_device, load_weights, load_embeddings, create_embeddings_matrix\n",
    "from vocab import Vocab\n",
    "from train2 import create_model\n",
    "from preprocess import load_dataset, create_dataset_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "from models import MLPClassifier, Baseline_Embeddings\n",
    "from models import Seq2Seq, MLP_D, MLP_G, MLP_I, MLP_I_AE, JSDistance, Seq2SeqCAE, Baseline_Embeddings, Baseline_LSTM\n",
    "from utils import to_gpu, Corpus, batchify, SNLIDataset, collate_snli\n",
    "import random\n",
    "import pickle as pkl\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = 'train.jaw89lze'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data/experiments')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXPERIMENTS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment.load(EXPERIMENTS_DIR, exp_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 453655, val: 10000, test: 10000\n",
      "Vocab: 9419, style vocab: 2\n",
      "W_emb: (9419, 300)\n"
     ]
    }
   ],
   "source": [
    "preprocess_exp = Experiment.load(EXPERIMENTS_DIR, exp.config.preprocess_exp_id)\n",
    "dataset_train, dataset_val, dataset_test, vocab, style_vocab, W_emb = load_dataset(preprocess_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_reader = create_dataset_reader(preprocess_exp.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(exp.config, vocab, style_vocab, dataset_train.max_len, W_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_weights(model, exp.experiment_dir.joinpath('best.th'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inputs(instances):\n",
    "    if not isinstance(instances, list):\n",
    "        instances = [instances,]\n",
    "        \n",
    "    if not isinstance(instances[0], dict):\n",
    "        sentences = [\n",
    "            dataset_reader.preprocess_sentence(dataset_reader.spacy( dataset_reader.clean_sentence(sent)))\n",
    "            for sent in instances\n",
    "        ]\n",
    "        \n",
    "        style = list(style_vocab.token2id.keys())[0]\n",
    "        instances = [\n",
    "            {\n",
    "                'sentence': sent,\n",
    "                'style': style,\n",
    "            }\n",
    "            for sent in sentences\n",
    "        ]\n",
    "#         print(\"INST!\")\n",
    "        for inst in instances:\n",
    "#             print(inst)\n",
    "            inst_encoded = dataset_train.encode_instance(inst)\n",
    "            inst.update(inst_encoded)            \n",
    "    \n",
    "    \n",
    "    instances = [\n",
    "        {\n",
    "            'sentence': inst['sentence_enc'],\n",
    "            'style': inst['style_enc'],\n",
    "        } \n",
    "        for inst in instances\n",
    "    ]\n",
    "    \n",
    "    instances = default_collate(instances)\n",
    "    instances = to_device(instances)      \n",
    "    \n",
    "    return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(outputs):\n",
    "    predicted_indices = outputs[\"predictions\"]\n",
    "    end_idx = vocab[Vocab.END_TOKEN]\n",
    "    \n",
    "    if not isinstance(predicted_indices, np.ndarray):\n",
    "        predicted_indices = predicted_indices.detach().cpu().numpy()\n",
    "\n",
    "    all_predicted_tokens = []\n",
    "    for indices in predicted_indices:\n",
    "        indices = list(indices)\n",
    "\n",
    "        # Collect indices till the first end_symbol\n",
    "        if end_idx in indices:\n",
    "            indices = indices[:indices.index(end_idx)]\n",
    "\n",
    "        predicted_tokens = [vocab.id2token[x] for x in indices]\n",
    "        all_predicted_tokens.append(predicted_tokens)\n",
    "        \n",
    "    return all_predicted_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence =  ' '.join(dataset_val.instances[1]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'they are really good people .'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = create_inputs(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': tensor([[136,  55,  29, 380, 368,   8,   2,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0]], device='cuda:0'),\n",
       " 'style': tensor([0], device='cuda:0')}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = get_sentences(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'they are really good people .'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swap style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_styles = list(style_vocab.token2id.keys()) #['negative', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['negative', 'positive'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style_vocab.token2id.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative', 'positive']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences0 = [s for s in dataset_val.instances if s['style'] == possible_styles[0]]\n",
    "sentences1 = [s for s in dataset_val.instances if s['style'] == possible_styles[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "535 the lady at the counter was friendly and took our order w/ no problems .\n",
      "3659 it was not very busy for saturday night .\n",
      "3933 this evening 's dinner was a disaster !\n",
      "3311 service was great but the number oz bone in ribeye was very disappointing .\n",
      "2035 not even worth the one star rating we are forced to give !\n"
     ]
    }
   ],
   "source": [
    "for i in np.random.choice(np.arange(len(sentences0)), 5):\n",
    "    print(i, ' '.join(sentences0[i]['sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3948 she was great .\n",
      "1506 other than that everything else is great !\n",
      "4390 the biscuits here are always the perfect balance between crunchy and thick .\n",
      "700 i also tried the spinach and egg bagel , also very good !\n",
      "545 our guests raved and raved about how beautiful and delicious the cake was !\n"
     ]
    }
   ],
   "source": [
    "for i in np.random.choice(np.arange(len(sentences1)), 5):\n",
    "    print(i, ' '.join(sentences1[i]['sentence']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3874 the rice had hard things in it .\n"
     ]
    }
   ],
   "source": [
    "print(3874, ' '.join(sentences0[3874]['sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "target0 = 3874 # np.random.choice(np.arange(len(sentences0)))\n",
    "target1 = 4935 # np.random.choice(np.arange(len(sentences0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rice had hard things in it .\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(sentences0[target0]['sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which is awesome !\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(sentences1[target1]['sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = create_inputs([\n",
    "    sentences0[target0],\n",
    "    sentences1[target1],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_hidden = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_hidden['style_hidden'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_hidden['meaning_hidden'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_decoded = model.decode(z_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sentences = get_sentences(original_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rice had hard things in it .\n",
      "which is awesome !\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(original_sentences[0]))\n",
    "print(' '.join(original_sentences[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model(create_inputs('sophistication extraordinary asdsadasdadsadasdsadasdsadasdadsadsd <unk>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['everything', ',', ',', 'with', 'the', 'experience', 'of', 'gorgeous', '.']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentences(model.decode(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0304,  0.3485, -0.1832,  0.0168,  0.2922, -0.2489,  0.4045,  1.0091,\n",
       "         0.0626, -0.0538,  0.2468,  0.0552, -0.1199, -0.1482,  0.0519, -0.3881,\n",
       "         0.0385,  0.0611, -0.2959, -0.0111,  0.4923,  0.1755,  0.2372, -0.1484,\n",
       "        -0.2288, -0.1240, -0.2253, -0.0819, -0.2461, -0.0367,  0.2760,  0.1065,\n",
       "         0.0356, -0.1010, -0.1400,  0.2693, -0.2108, -0.1767,  0.4459,  0.4920,\n",
       "        -0.5315,  0.2920, -0.2592,  0.0526,  0.0453, -0.3169,  0.0054,  0.0895,\n",
       "         0.2257, -0.0154, -0.1207, -0.1999,  0.0278,  0.1244, -0.0796,  0.0468,\n",
       "         0.0466, -0.1769, -0.3507, -0.2137,  0.2887,  0.2937, -0.2503,  0.1329,\n",
       "        -0.1793,  0.1662,  0.1337,  0.4106, -0.1068, -0.0255, -0.2377,  0.1682,\n",
       "        -0.0984,  0.4288, -0.0108, -0.1960,  0.1689,  0.2532, -0.2159, -0.1833,\n",
       "        -0.0642,  0.3634,  0.1607,  0.0532, -0.0969, -0.2231, -0.0929,  0.1783,\n",
       "         0.2294, -0.1193, -0.4915, -0.2499, -0.1053, -0.3476,  0.6208, -0.0799,\n",
       "        -0.0934,  0.1069,  0.0144, -0.1646, -0.4841, -0.0200, -0.1935,  0.2375,\n",
       "        -0.2944, -0.1478,  0.4031, -0.2966,  0.2563, -0.1917,  0.1323,  0.2579,\n",
       "        -0.0809, -0.1463, -0.3048, -0.9382, -0.1653, -0.3303, -0.0458, -0.1340,\n",
       "         0.0167,  0.1845,  0.3623,  0.2666,  0.0083,  0.2875, -0.0373, -0.3038],\n",
       "       device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_hidden['meaning_hidden'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, z_hidden['style_hidden'][0].shape[0]):\n",
    "    z_hidden['style_hidden'][0][i] = 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_hidden['style_hidden'][0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
       "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
       "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
       "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
       "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
       "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
       "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
       "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
       "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
       "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
       "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
       "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
       "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
       "        0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000, 0.9000,\n",
       "        0.9000, 0.9000], device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_hidden['style_hidden'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_hidden_swapped = {\n",
    "    'meaning_hidden': torch.stack([\n",
    "        z_hidden['meaning_hidden'][0].clone(),\n",
    "        #z_hidden['meaning_hidden'][1].clone(),        \n",
    "    ], dim=0),\n",
    "    'style_hidden': torch.stack([\n",
    "        z_hidden['style_hidden'][0].clone(),\n",
    "        #z_hidden['style_hidden'][0].clone(),        \n",
    "    ], dim=0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "swaped_decoded = model.decode(z_hidden_swapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "swaped_sentences = get_sentences(swaped_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rice had hard things in it .\n",
      "\n",
      "i am only going for that like anyone !\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(original_sentences[0]))\n",
    "# print(' '.join(original_sentences[1]))\n",
    "print()\n",
    "print(' '.join(swaped_sentences[0]))\n",
    "# print(' '.join(swaped_sentences[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original vocab 41574; pruned to 11004\n",
      "Number of sentences dropped from ./data/classifier/train.txt: 448221 out of 549367 total\n",
      "original vocab 41574; pruned to 11004\n",
      "Number of sentences dropped from ./data/classifier/test.txt: 8288 out of 9824 total\n"
     ]
    }
   ],
   "source": [
    "#python3.6 train_surrogate.py --data_path ./data/classifier --save_path game_output/ --classifier_path ./data --load_pretrained .\n",
    "cur_dir = '.'\n",
    "\n",
    "with open(cur_dir + '/vocab.json', 'r') as fin:\n",
    "    corpus_vocab = json.load(fin)\n",
    "\n",
    "corpus_train = SNLIDataset(train=True, vocab_size=11004-4, path='./data/classifier')\n",
    "corpus_test = SNLIDataset(train=False, vocab_size=11004-4, path='./data/classifier')\n",
    "trainloader= torch.utils.data.DataLoader(corpus_train, batch_size = 32, collate_fn=collate_snli, shuffle=True)\n",
    "train_iter = iter(trainloader)\n",
    "testloader= torch.utils.data.DataLoader(corpus_test, batch_size = 32, collate_fn=collate_snli, shuffle=False)\n",
    "random.seed(1111)\n",
    "np.random.seed(1111)\n",
    "torch.manual_seed(1111)\n",
    "\n",
    "EPS = 3e-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/game/.local/lib/python3.6/site-packages/torch/serialization.py:435: SourceChangeWarning: source code of class 'models.Seq2SeqCAE' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline_Embeddings(\n",
      "  (embedding_prem): Embedding(11004, 100)\n",
      "  (embedding_hypo): Embedding(11004, 100)\n",
      "  (linear): Linear(in_features=200, out_features=3, bias=True)\n",
      ")\n",
      "Seq2SeqCAE(\n",
      "  (embedding): Embedding(11004, 300)\n",
      "  (embedding_decoder): Embedding(11004, 300)\n",
      "  (encoder): Sequential(\n",
      "    (layer-1): Conv1d(300, 500, kernel_size=(3,), stride=(1,))\n",
      "    (bn-1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation-1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (layer-2): Conv1d(500, 700, kernel_size=(3,), stride=(2,))\n",
      "    (bn-2): BatchNorm1d(700, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation-2): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (layer-3): Conv1d(700, 1000, kernel_size=(3,), stride=(2,))\n",
      "    (bn-3): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation-3): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (linear): Linear(in_features=1000, out_features=300, bias=True)\n",
      "  (decoder): LSTM(600, 300, batch_first=True)\n",
      "  (linear_dec): Linear(in_features=300, out_features=11004, bias=True)\n",
      ")\n",
      "MLP_I(\n",
      "  (layer1): Linear(in_features=300, out_features=300, bias=True)\n",
      "  (bn1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activation1): ReLU()\n",
      "  (layer2): Linear(in_features=300, out_features=300, bias=True)\n",
      "  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (activation2): ReLU()\n",
      "  (layer7): Linear(in_features=300, out_features=100, bias=True)\n",
      ")\n",
      "MLPClassifier(\n",
      "  (layers): Sequential(\n",
      "    (layer0): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (bn0): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation0): ReLU()\n",
      "    (layer1): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (bn1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (activation1): ReLU()\n",
      "  )\n",
      "  (linear): Linear(in_features=50, out_features=3, bias=True)\n",
      "  (log_softmax): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "autoencoder = torch.load(open(cur_dir + '/models/autoencoder_model.pt', 'rb'))\n",
    "#gan_gen = torch.load(open(cur_dir + '/models/gan_gen_model.pt', 'rb'))\n",
    "#gan_disc = torch.load(open(cur_dir + '/models/gan_disc_model.pt', 'rb'))\n",
    "inverter = torch.load(open(cur_dir + '/models/inverter_model.pt', 'rb'))\n",
    "\n",
    "classifier1 = Baseline_Embeddings(100, vocab_size=11004)\n",
    "#classifier1 = Baseline_LSTM(100,300,maxlen=args.maxlen, gpu=args.cuda)\n",
    "classifier1.load_state_dict(torch.load('./models' + \"/baseline/model_emb.pt\"))\n",
    "vocab_classifier1 = pkl.load(open('./models' + \"/vocab.pkl\", 'rb'))\n",
    "\n",
    "mlp_classifier = MLPClassifier(100 * 2, 3, layers='100-50')\n",
    "#if not args.train_mode:\n",
    "mlp_classifier.load_state_dict(torch.load('./game_output'+'/surrogate{0}.pt'.format('100-50')))\n",
    "\n",
    "print(classifier1)\n",
    "print(autoencoder)\n",
    "print(inverter)\n",
    "print(mlp_classifier)\n",
    "\n",
    "optimizer = optim.Adam(mlp_classifier.parameters(),\n",
    "                           lr=1e03,\n",
    "                           betas=(0.9, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def evaluate_model():\n",
    "    classifier1.eval()\n",
    "\n",
    "    test_iter = iter(trainloader)\n",
    "    correct=0\n",
    "    total=0\n",
    "    for batch in test_iter:\n",
    "        premise, hypothesis, target, _, _, _, _ = batch\n",
    "\n",
    "        if args.cuda:\n",
    "            premise=premise.cuda()\n",
    "            hypothesis = hypothesis.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "        prob_distrib = classifier1.forward((premise, hypothesis))\n",
    "        predictions = np.argmax(prob_distrib.data.cpu().numpy(), 1)\n",
    "        correct+=len(np.where(target.data.cpu().numpy()==predictions)[0])\n",
    "        total+=premise.size(0)\n",
    "    acc=correct/float(total)\n",
    "    print(\"Accuracy:{0}\".format(acc))\n",
    "    return acc\n",
    "\n",
    "autoencoder.gpu = True\n",
    "autoencoder = autoencoder.cuda()\n",
    "autoencoder.start_symbols = autoencoder.start_symbols.cuda()\n",
    "#gan_gen = gan_gen.cuda()\n",
    "#gan_disc = gan_disc.cuda()\n",
    "classifier1 = classifier1.cuda()\n",
    "inverter = inverter.cuda()\n",
    "mlp_classifier = mlp_classifier.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_process(premise, hypothesis, target, premise_words, hypothesis_words, premise_length, hypothesis_length):\n",
    "    #mx = target.max().item()\n",
    "    #assert(mx >= 0 and mx < 3)\n",
    "    #for s, s_w in zip(premise, premise_words):\n",
    "    #    for i, w in zip(s, s_w):\n",
    "    #        assert(corpus_vocab.get(w, 3) == i)\n",
    "    #print(hypothesis_words, flush=True)\n",
    "    autoencoder.eval()\n",
    "    inverter.eval()\n",
    "    classifier1.eval()\n",
    "    mlp_classifier.train()\n",
    "\n",
    "    #print(premise.max().item(), flush=True)\n",
    "    #print(hypothesis.max().item(), flush=True)\n",
    "\n",
    "    premise_idx = torch.tensor([[corpus_vocab.get(w, 3) for w in s] for s in premise_words]).cuda()\n",
    "    hypothesis_idx = torch.tensor([[corpus_vocab.get(w, 3) for w in s] for s in hypothesis_words]).cuda()\n",
    "\n",
    "    c_prem = autoencoder.encode(premise_idx, premise_length, noise=False)\n",
    "    z_prem = inverter(c_prem).detach()\n",
    "\n",
    "    c_hypo = autoencoder.encode(hypothesis_idx, hypothesis_length, noise=False)\n",
    "    z_hypo = inverter(c_hypo).detach()\n",
    "\n",
    "    # z_comb = nn.cat((z_prem, z_hypo), 0).detach()\n",
    "\n",
    "    output = mlp_classifier(z_prem, z_hypo)\n",
    "    gold = classifier1((premise, hypothesis)).detach()\n",
    "\n",
    "    #print(output.shape, flush=True)\n",
    "    #print(gold.shape, flush=True)\n",
    "\n",
    "    acc = (torch.argmax(gold, 1) == target).to(torch.float32).mean().item()\n",
    "    acc_surrogate = (torch.argmax(output, 1) == target).to(torch.float32).mean().item()\n",
    "\n",
    "\n",
    "    loss = -torch.mean(torch.sum(output * F.softmax(gold, dim=1), 1), 0)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item(), acc, acc_surrogate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb(criterion, premise, hypothesis, target, premise_words, hypothesis_words, premise_length, hypothesis_length):\n",
    "    autoencoder.eval()\n",
    "    inverter.eval()\n",
    "    classifier1.eval()\n",
    "    mlp_classifier.eval()\n",
    "\n",
    "    premise_words = [premise_words]\n",
    "    hypothesis_words = [hypothesis_words]\n",
    "    premise_length = [premise_length]\n",
    "    hypothesis_length = [hypothesis_length]\n",
    "\n",
    "\n",
    "    premise_idx = torch.tensor([[corpus_vocab.get(w, 3) for w in s] for s in premise_words]).cuda()\n",
    "    hypothesis_idx = torch.tensor([[corpus_vocab.get(w, 3) for w in s] for s in hypothesis_words]).cuda()\n",
    "#     print('premise_idx = ' + str(premise_idx))\n",
    "#     print('hypothesis-idx = ' + str(hypothesis_idx))\n",
    "#     c_prem = autoencoder.encode(premise_idx, premise_length, noise=False)\n",
    "    c_prem = create_inputs(premise_words[0])\n",
    "    print(\"C_PREM\")\n",
    "    print(c_prem)\n",
    "#     c_prem = create_inputs(' '.join(premise_words[0]))\n",
    "    z_prem = inverter(c_prem).detach()\n",
    "#     print('c_prem = ' + str(c_prem))\n",
    "#     print('z_prem = ' + str(z_prem))\n",
    "    c_hypo = autoencoder.encode(hypothesis_idx, hypothesis_length, noise=False).detach()\n",
    "    c_hypo.requires_grad = True\n",
    "    z_hypo = inverter(c_hypo)\n",
    "\n",
    "\n",
    "    premise = premise.unsqueeze(0)\n",
    "    hypothesis = hypothesis.unsqueeze(0)\n",
    "    target = target.unsqueeze(0)\n",
    "\n",
    "    output = mlp_classifier(z_prem, z_hypo)\n",
    "\n",
    "    loss = criterion(output, target)\n",
    "    mlp_classifier.zero_grad()\n",
    "    inverter.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    direction = torch.sign(c_hypo.grad)\n",
    "    nc_hypo = c_hypo + EPS * direction\n",
    "    nhypo_idx = autoencoder.generate(nc_hypo, 10, False)\n",
    "\n",
    "    return nhypo_idx.squeeze(0).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_pred(pw, hw):\n",
    "    classifier1.eval()\n",
    "\n",
    "    premise_idx = torch.tensor([vocab_classifier1.get(w, 3) for w in pw]).cuda().unsqueeze(0)\n",
    "    hypothesis_idx = torch.tensor([vocab_classifier1.get(w, 3) for w in hw]).cuda().unsqueeze(0)\n",
    "\n",
    "    return F.softmax(classifier1((premise_idx, hypothesis_idx)), 1).squeeze(0).cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximum(arr):\n",
    "    a = -1\n",
    "    t = 0\n",
    "    for i in range(len(arr)):\n",
    "        if arr[i] > a:\n",
    "            a = arr[i]\n",
    "            t = i\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vocab.UNK_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_PREM\n",
      "{'sentence': tensor([[   0,    0,    0,    2,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [ 747,    2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [3652,    2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [ 726,    2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [  24,    2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [1525,    2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   8,    2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,    0,    0,    2,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   0, 3720,    0,    2,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]], device='cuda:0'), 'style': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-dfd2e134c539>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mnh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperturb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Target '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-67e1003342ab>\u001b[0m in \u001b[0;36mperturb\u001b[0;34m(criterion, premise, hypothesis, target, premise_words, hypothesis_words, premise_length, hypothesis_length)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_prem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#     c_prem = create_inputs(' '.join(premise_words[0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mz_prem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_prem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;31m#     print('c_prem = ' + str(c_prem))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#     print('z_prem = ' + str(z_prem))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/natural-adversary/text/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0mOutput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0m_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \"\"\"\n\u001b[0;32m-> 1350\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "niter = 0\n",
    "evaluate = 0\n",
    "nevaluate = 0\n",
    "idx2words = dict(map(lambda x: (x[1], x[0]), corpus_vocab.items()))\n",
    "while niter < len(testloader):\n",
    "    niter += 1\n",
    "    batch = train_iter.next()\n",
    "    for p, h, t, pw, hw, pl, hl in zip(*batch):\n",
    "        nh = perturb(criterion, p.cuda(), h.cuda(), t.cuda(), pw, hw, pl, hl)\n",
    "        print('--------------------------------')\n",
    "        print('Target ', t)\n",
    "#         print(' '.join(pw))\n",
    "#         temp = ' '.join(pw)\n",
    "        nhw = (['<sos>'] + [idx2words[i] for i in nh])[:10]\n",
    "        print(' '.join(nhw))\n",
    "        print('Old ', classifier_pred(pw, hw))\n",
    "        print('New ', classifier_pred(pw, nhw))\n",
    "        print('Old Pred: ', maximum(classifier_pred(pw, hw)))\n",
    "        print('New Pred: ', maximum(classifier_pred(pw, nhw)))\n",
    "        print('Good: ', maximum(classifier_pred(pw, hw)) != maximum(classifier_pred(pw, nhw)))\n",
    "        evaluate = evaluate + int(maximum(classifier_pred(pw, hw)) != maximum(classifier_pred(pw, nhw)))\n",
    "        nevaluate = nevaluate + 1\n",
    "    break\n",
    "print(evaluate / nevaluate)\n",
    "print(nevaluate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(vocab.get('aasdasdasdsad', 0), dtype=np.long)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
